version: '3.8'

# ðŸš€ Complete AI-Powered Authentication System
# Single Docker Compose setup with everything included:
# - PostgreSQL Database
# - Redis Cache for AI models  
# - Temporal Server & UI
# - AI-Enhanced Backend with Ollama integration
# - React Frontend
# - Ollama AI Server for local AI capabilities

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: oauth2_auth
      POSTGRES_USER: oauth2_user
      POSTGRES_PASSWORD: oauth2_password_change_in_production
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/app/database/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U oauth2_user -d oauth2_auth"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - auth-network
    restart: unless-stopped

  # Redis for AI model caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - auth-network
    restart: unless-stopped

  # Temporal Server
  temporal:
    image: temporalio/auto-setup:latest
    ports:
      - "7233:7233"
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=oauth2_user
      - POSTGRES_PWD=oauth2_password_change_in_production
      - POSTGRES_SEEDS=postgres
      - POSTGRES_DB=temporal
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "temporal", "workflow", "list", "--address", "temporal:7233"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - auth-network
    restart: unless-stopped

  # Temporal Web UI
  temporal-ui:
    image: temporalio/ui:latest
    ports:
      - "8081:8080"
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    depends_on:
      temporal:
        condition: service_healthy
    networks:
      - auth-network
    restart: unless-stopped

  # Ollama AI Server (Local AI)
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_MODELS=llama3,phi3,mistral
    networks:
      - auth-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - gpu
    
  # Ollama CPU version (fallback)
  ollama-cpu:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - auth-network
    restart: unless-stopped
    profiles:
      - cpu

  # AI-Enhanced FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # Database
      - DATABASE_URL=postgresql://oauth2_user:oauth2_password_change_in_production@postgres:5432/oauth2_auth
      
      # JWT Configuration
      - JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
      - JWT_ALGORITHM=HS256
      - JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
      - JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
      
      # Email Configuration (configure with your SMTP provider)
      - SMTP_SERVER=smtp.gmail.com
      - SMTP_PORT=587
      - SMTP_USERNAME=${SMTP_USERNAME:-}
      - SMTP_PASSWORD=${SMTP_PASSWORD:-}
      
      # OAuth2 Configuration
      - OAUTH2_CLIENT_ID=oauth2-client
      - OAUTH2_CLIENT_SECRET=oauth2-client-secret
      - OAUTH2_REDIRECT_URI=http://localhost:3000/callback
      
      # URLs
      - FRONTEND_URL=http://localhost:3000
      - BACKEND_URL=http://localhost:8000
      
      # Temporal Configuration
      - TEMPORAL_HOST=temporal
      - TEMPORAL_PORT=7233
      - TEMPORAL_NAMESPACE=default
      
      # Redis Configuration for AI model caching
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      
      # AI Configuration (all optional)
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      
      # AI Settings
      - AI_MODEL_CACHE_TTL=86400
      - AI_FALLBACK_ENABLED=true
      - AI_CONFIDENCE_THRESHOLD=0.7
      
    volumes:
      - ./backend:/app
      - ai_models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      temporal:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - auth-network
    restart: unless-stopped

  # Temporal Worker with AI capabilities
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      # Same environment as backend
      - DATABASE_URL=postgresql://oauth2_user:oauth2_password_change_in_production@postgres:5432/oauth2_auth
      - JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
      - TEMPORAL_HOST=temporal
      - TEMPORAL_PORT=7233
      - TEMPORAL_NAMESPACE=default
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - AI_MODEL_CACHE_TTL=86400
      - AI_FALLBACK_ENABLED=true
    volumes:
      - ./backend:/app
      - ai_models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      temporal:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    command: ["python", "worker.py"]
    networks:
      - auth-network
    restart: unless-stopped

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_TEMPORAL_UI_URL=http://localhost:8081
      - REACT_APP_AI_ENABLED=true
      - CHOKIDAR_USEPOLLING=true
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - auth-network
    restart: unless-stopped

  # Model Initialization Service (downloads AI models)
  model-init:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - auth-network
    command: >
      sh -c "
        echo 'Initializing AI models...' &&
        ollama serve &
        sleep 10 &&
        echo 'Downloading llama3 model...' &&
        ollama pull llama3 &&
        echo 'Downloading phi3 model...' &&
        ollama pull phi3 &&
        echo 'Models downloaded successfully!' &&
        sleep 5
      "
    profiles:
      - init

networks:
  auth-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ai_models:
    driver: local
  ollama_data:
    driver: local

# ðŸš€ Usage Instructions:
#
# 1. Basic Setup (CPU-only):
#    docker-compose -f docker-compose.complete.yml --profile cpu up -d
#
# 2. GPU-Enabled Setup (if NVIDIA GPU available):
#    docker-compose -f docker-compose.complete.yml --profile gpu up -d
#
# 3. Initialize AI models (run once):
#    docker-compose -f docker-compose.complete.yml --profile init run model-init
#
# 4. Full system with model initialization:
#    docker-compose -f docker-compose.complete.yml --profile cpu --profile init up -d
#
# 5. Environment variables (.env file):
#    Create .env file with:
#    OPENAI_API_KEY=your-openai-key
#    ANTHROPIC_API_KEY=your-anthropic-key
#    SMTP_USERNAME=your-email@gmail.com
#    SMTP_PASSWORD=your-app-password
#
# 6. Access points:
#    - Frontend: http://localhost:3000
#    - Backend API: http://localhost:8000
#    - API Docs: http://localhost:8000/docs
#    - Temporal UI: http://localhost:8081
#    - AI Health: http://localhost:8000/ai/health
#    - Ollama: http://localhost:11434
#
# 7. Test AI features:
#    curl http://localhost:8000/ai/test-password-analysis
#    curl http://localhost:8000/ai/test-fraud-detection